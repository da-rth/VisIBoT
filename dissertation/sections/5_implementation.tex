% Checked with Grammarly - 22/03/2021

\chapter{Implementation}

% =========================================

This chapter discusses the various implementation stages involved during the VisiBot Processing System and Interactive Web Application development and deployment. Such sections define the technologies, architectural design patterns, development practices, and deployment strategies used throughout the development process.

\section{Distributed Real-time Processing System}

\subsection{Message-based task queues with Celery and Redis}

Written in Python 3.9 \citep{Python39}, the VisiBot Processing System utilises several internal and external modules, services, and frameworks to create a flexible and reliable analysis system based on the Message Broker design pattern. I chose the Python programming language primarily due to the extensive availability of open-source community libraries, including various web development frameworks, API wrappers, and data analytic tools.

One such library used is Celery \citep{Celery}, a python-based asynchronous task queuing framework modelled on the Message Broker design pattern. Redis, an open-source data structure store commonly used for databasing, caching, and message brokering \citep{Redis}, In is used conjunction with Celery to enable the processing of vast amounts of messages across distributed worker instances. Through the queuing of programmatic tasks as messages, high quantities of synchronous, or otherwise, time-consuming tasks are actively consumed by Celery workers through interaction with a central broker system. Celery supports integration with various message brokers, including RabbitMQ, Amazon SQS, Redis, and Zookeeper. Within the context of this project, Redis was chosen as the primary message broker for VisiBot.

Celery tasks are created by an application and routed, stored, and eventually consumed through a broker system by a cluster of Celery workers. These workers can be distributed across several systems and can be configured automatically based on the queue's size and the work-load. Celery workers also support the execution of tasks in parallel via multi-processing, enabling the swift and concurrent performance of time-consuming tasks that might otherwise bottle-neck synchronous applications. The VisiBot Processing System utilises Celery workers to analyse, identify, and extract legitimate botnet traffic from honeypot sources and sandboxes. As this process can be time-consuming on synchronous systems, the adoption of a Message Broker design pattern through Celery and Redis ensures that analysis tasks are completed concurrently and reliably.

To monitor the VisiBot task queue, Flower, a python-based Celery monitoring tool by \citet{CeleryFlower}, was used. Accessible remotely through a web-application, Flower allows for monitoring task queues, celery workers, and successful or failed tasks. As the stack-traces for all unsuccessful tasks are logged by Celery, such traces are remotely accessible through accessing the Flower dashboard, allowing for a convenient means for identifying and debugging worker run-time exceptions from within a deployed environment. The flower web interface has been protected with user authentication, as it allows users to remotely manage workers and view potentially confidential information, such as stack-traces. A screenshot of the dashboard is shown below:

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/flower-panel.png}
    \caption{Flower Dashboard. Celery workers are represented in a table as rows.}
    \label{fig:flower_dashboard} 
\end{figure}

\subsection{Docker}

As the VisiBot task queuing system and analysis process utilises various applications, celery workers, servers, and external services, the setup and deployment procedure of such a system can introduce a multitude of complexities and anomalies due to varying environmental factors such as operating system, package managers, system architecture, etc. Thus, to streamline the setup and deployment process, all applications, services, and workers utilised by the system have been encapsulated within a multi-container Docker application using the command-line tool Docker Compose \citep{DockerCompose}. 

A unique feature provided by docker is that of image scalability. By containerising a single celery worker within a docker image, it can dynamically be scaled to allow multiple celery workers' instantaneous creation. The number of workers is scaled by appending the \texttt{docker-compose} command with the \texttt{--scale worker N} argument. For example, running the docker application with the argument \texttt{--scale worker 10} will prompt Docker to create 10 VisiBot Celery worker containers. Each container will initialise a new celery worker instance and connect to the Redis broker service, which is also containerised within the docker application. All other services and applications used by the VisiBot workers and processing system have also been containerised, including a locally accessible tor server, honeypot result scheduling system, Flask Web API Application, MaxMind GeoIP2 Updater, and a remotely accessible instance of Flower. Docker enables shared access storage between containers through the creation of containerised volumes. Additionally, an \texttt{.env} file, initially populated with a set of default environment variables, is automatically read by docker-compose upon initialisation. This allows the user to change various aspects of the processing system, such as API keys and paths, without modifying any code directly.

As VisiBot workers use shared MaxMind GeoIP2 databases \citep{MaxMind} during analysis tasks, a shared volume was created such that the VisiBot workers could query a shared database hosted within the GeoIP container. Upon initialisation, the GeoIP creates a Cron-job using \texttt{crontab} \citep{Crontab} which, executes a GeoIP2 updating utility every week. This utility writes the latest versions of all MaxMind GeoIP2 databases to \texttt{/usr/local/share/GeoIP2}. By modifying the docker configuration of VisiBot's \texttt{docker-compose.yml}, this path was defined as a shared path accessible to all workers. A visualisation of the relationships between all docker containers within the VisiBot Processing System is shown below:


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.75\linewidth]{graphs/docker-compose.png}
    \caption{Visualisation of VisiBot Docker-Compose Containers. Reverse Engineered using docker-compose-viz. Containers are represented as rectangles and exposed container ports as circles.}
    \label{fig:docker_graph} 
\end{figure}



% =========================================


\section{VisiBot Processing System}

\subsection{Database Record Storage using MongoDB}

Developed by \citet{MongoDB}, MongoDB is a Document-Oriented No-SQL database with extensive cross-platform support, allowing for the storage of documents represented in JavaScript Object Notation (JSON), a highly supported human-readable standard format. The VisiBot Processing System uses MongoDB widely to manage and store complex, large, and nested data objects through MongoEngine, an open-source python object data mapper for MongoDB \citep{MongoEngine}. As Documents are represented in a standard JSON format, such documents can be easily created, managed, and accessed by mapping MongoDB documents to standard Python objects and types, such as dictionaries and lists. Additionally, as this file format is widely accepted by various other programming languages, libraries/frameworks, and software applications, data collections stored within MongoDB Documents can be easily imported/exported, manipulated, and analysed by various popular data science, analytics and visualisation libraries.

Like relational databases such as PostgreSQL and MySQL, entity relationships of various cardinalities can also be established within MongoDB. However, unlike traditional relational databases, certain relationships such as One-to-One and One-to-Many can be represented by using embedded MongoDB documents (JSON Objects). This allows for the nesting of documents such that relational attributes are easily accessible and represented logically. Additionally, MongoDB allows for representing One-to-Many relationships by creating and referencing primary keys attributes through document reference fields. VisiBot uses such relationships, enabling the linkage of documents containing information for botnet IP addresses, Autonomous Systems, malware analysis reports, and more. A full Entity Relationship diagram of all of the VisiBot Processing database relationships can be seen in Appendix \ref{appendix_a1}.

All data collected by the VisiBot Processing System is securely stored, managed, and accessed through a remotely accessible instance of MongoDB hosted through the MongoDB Atlas \citep{MongoDBAtlas}.

\subsection{Honeypot Data Collection}

All honeypot information processed by VisiBot is provided by \citet{BadPackets}, a leading provider of Cyber Threat Intelligence information on emerging threats, DDoS botnets, and network abuse. The honeypots hosted by Bad Packets are strategically deployed across a diverse set of network providers based in multiple countries and regions, including Australia, Brazil, Canada, France, Germany, India, Japan, Netherlands, Russia, Singapore, Taiwan, The Middle East, the United Kingdom, and the United States. Such honeypot servers are configured to emulate commonly targeted hosts specific to botnet traffic by mimicking various IoT devices, consumer-grade routers, enterprise VPN endpoints. Additionally, sinkhole domains previously used by threat-actors are employed to point potential botnet traffic to the honeypots.

Accessible through an authenticated REST API, the Bad Packets honeypot service is queried on an hourly basis from within a containerised task scheduler application written in Python. Using the python \texttt{requests} library \citep{PythonRequests}, the BadPackets API is repeatedly queried for honeypot packet results. Each result is converted into a Python dictionary and is appended to a list containing all results. For an example of a Bad Packets honeypot result, see \ref{appendix_a2}.

Once all results within the last hour have been collected, the scheduler connects to the VisiBot Celery broker (Redis), hosted within a neighbouring docker container. The scheduler begins to create analysis tasks for each packet result. Task creation is requested through the client executing \texttt{Celery.send\_task}, passing the task name as a string and the result dictionary for analysis as an argument. Following this, tasks are created as pending messages within the broker and are actively consumed (executed) by available Celery workers. Once task creation has completed, the scheduler will wait until the next hour before extracting more results from Bad Packets, as new packet data is made available through the API at the beginning of every hour. All Celery can be viewed in the Flower web dashboard hosted from within a separate docker container:

\begin{lstlisting}[caption={Example output of VisiBot Processing Scheduler.}]
VisiBot collection event activated. Collecting data from Bad Packets API.
Querying Bad Packets (last seen after 2021-03-01T21:00:00Z)
Queried 927/927 results
Creating processing tasks for 927 results.
Workers are now running tasks in the background. Visit http:/flower:5555 to view progress.
\end{lstlisting}

Upon receiving tasks from the Celery broker, workers will begin to perform analysis on received packet data. As the analysis procedure involves actively reading and writing from a database, each worker is configured to execute at most one concurrent job from the broker at any given time to avoid database connection locks. The honeypot packet analysis process is separated into multiple stages, spanning from malware payload URL extraction and traffic classification to sandbox analysis initialisation. 

\subsection{Malware payload extraction}

As previously discussed, when a device is infected with botnet malware, it will begin to scan for open ports of vulnerable devices and will attempt to infect such devices by sending malicious HTTP requests that contain command-line injection code. The injected code will likely attempt to download and execute a malware binary using command-line utilities such as \texttt{wget}, \texttt{curl}, or \texttt{tftp}. Such exploit attempts are commonly found within the \texttt{payload} or \texttt{post\_data} of a packet. By extracting the URL of the botnet malware payload, the binary can later be retrieved and analysed. 

\subsubsection{Noise removal and de-obfuscation}

The first stage of malware payload extraction involves the removal of noise and mitigation of the various obfuscation techniques employed by bad actors, such as botnet owners. Due to the high number of different devices being targeted and exploits used, the structure and syntax of the command-line injection code captured by honeypots can vary. Consider the following payloads strings:

%TC:ignore
\begin{lstlisting}[escapechar=@, caption={Example of noisy and obfuscated botnet payloads. Examples of noise are highlighted in \textbf{bold}, and obfuscation in \textit{italics}.}]
GET /language/Swedish${@\textbf{IFS}@}&&cd${@\textbf{IFS}@}/tmp;rm${@\textbf{IFS}@}-rf${@\textbf{IFS}@}*;wget${@\textbf{IFS}@}
http://[redacted_ip]:54134/Mozi.a;sh${@\textbf{IFS}@}/tmp/Mozi.a&>r&&tar${@\textbf{IFS}@}/string.js HTTP/1.0

GET /shell?cd /tmp; cp /bin/busybox yeet; >yeet; chmod 777 yeet; nohup wget
@\textit{http:/\textbackslash/}@[redacted_ip]:80/arm7 -O yeet || @\textit{nohup tftp -r arm7 -g [redacted\_ip] -l yeet}@;
chmod 777 yeet@\textbf{;./}@yeet Windows; rm -rf yeeter >/dev/null 2>&1 HTTP/1.1
\end{lstlisting}
%TC:endignore

As shown above, the first payload contains a lot of noise, as the \texttt{\$\{IFS\}} variable is used as an input field separator in-place of space characters. The second payload contains some light obfuscation employed to prevent regular expression patterns from matching URLs in the payload string. The first payload URL downloaded using \texttt{wget} has an escaped forward slash such that the pattern \texttt{http://} cannot be matched. Should the infiltrated system not have the \texttt{wget} command, the injected code also tries to download the binary using the \texttt{tftp} client. However, the malware payload URL is obscured using various command-line arguments, as the host of the URL is specified using the \texttt{-g} flag, the path using the \texttt{-r} flag, and the output using \texttt{-l}. These URLs can be re-built, but the presence of noise such as \texttt{\$\{IFS\}}-based spacing can make this process difficult. Through the manual inspection of several payload strings and post\_data contents, a short-list of noisy characters and sub-strings was created. This list is used during the cleaning process, such that significant noise is removed from both the payload and post\_data packet strings. Each string is decoded such that any URL encoded values, such as \texttt{\%20} spacing, are converted into plain text. Similarly, occurrences of the sub-string \texttt{\$\{IFS\}} are replaced with space characters, and the removal of inconsistent spacing before/after command-line semi-colon separators (\texttt{;}) is also implemented. Lastly, the removal and/or replacement of the characters \texttt{\textbackslash"'`\&|()+} ensure that all URLs and \texttt{wget/curl/tftp} commands are clean.

\subsubsection{Payload URL extraction and validation} 

Following the removal of noise, both the payload and post\_data strings are combined into a string which is parsed for payload URLs using several techniques. A conventional URL regular expression pattern is used to match all un-obfuscated URLs contained within the payload strings. However, as this expression matches all sub-strings that begin with \texttt{https?://}, a large proportion of partial or obfuscated payload URLs will not match this regular expression. For example, consider the following sub-strings:

\begin{itemize}
    \item \texttt{curl website.com/bin;}
    \item \texttt{wget 127.0.0.1:8080/bin;}
    \item \texttt{tftp -g 127.0.0.1:8080 -r bin;}
\end{itemize}

Due to the limitations of Regular Expression matching, the extraction process also utilises other methods of URL extraction. The python library \texttt{urlextract} \citep{URLExtract} partial URL strings containing domain names, such as \texttt{website.com/bin}, by matching any occurrences of Top Level Domains (TLD), such as \texttt{.com, .net} and \texttt{.org}, until a stop-character, such as white space, is reached. Domain Name Systems (DNS) are frequently used by bad actors such that IP addresses can be quickly changed without impacting communication between botnets and C2 servers. This method allows for the extraction and validation of domain names used for botnet propagation by bad actors, such as botnet owners, as partial domain-based URL strings are identified and re-formatted using the standard HTTP URL format. As these strings do not indicate an HTTP schema, the \texttt{http://} schema is used by default.

The practice of obfuscating payload URLs through executable arguments was quite common across inspected honeypot payload command-line injection strings, as shown in the example sub-strings above. However, the VisiBot Processing System also performs automatic re-construction of argument-based obfuscated URLs, particularly from data-transfer command-line tools such as \texttt{curl, wget} and \texttt{tftp}. A utility function is used to identify the position at which commands such as wget, curl, and tftp are executed, parsing the arguments following the initial command name until an end-of-line semi-colon (\texttt{;}) character is reached. Depending on the executable that is called, the function will look for and parse the contents of specific command-line arguments in order to extract the \texttt{host}, \texttt{port} and \texttt{path} of the obfuscated URL. For example, the helper function may identify usage of the \texttt{tftp} command and will extract the values passed within the \texttt{-g} and \texttt{-r} arguments, extracting the host, port, and path of the payload URL from the payload command-line injection string. Once extracted, the base URL is re-built through formatting extracted host, port, and path values within a standard http URL format: 

\begin{lstlisting}
url = "http://{host}:{port}/{path}".format("127.0.0.1", 8080, "bin")
>>> "http://127.0.0.1:8080/bin"
\end{lstlisting}

Following the base URL extraction process, GET requests are sent to each URL. The response data is parsed to identify if the URL leads to a binary executable, bash script, or non-executable file. All HTTP requests are routed through a Tor Proxy server hosted in a separate docker container from the celery workers for anonymity. All Non-executable URLs are disposed of and identified binary executables are immediately added to the list of URLs awaiting validation. Binary execution is identified by checking if the HTTP request's content-type header begins with \texttt{application/}, or the contents of the request contains an Executable and Linkable Format (ELF) header. However, the VisiBot Processing System's current limitation is that bash scripts cannot be executed from within the chosen sandbox environment. To combat this constraint, the worker will parse the contents of any bash script URLs and extract and store any nested URLs, which lead to binary executables using the same process as the payload string URL extraction stage. As bash scripts often include links malware for various types of architectures, this can lead to the extraction of up to 6 (or more) binaries. Bash scripts are identified by checking if the header content-type starts with \texttt{text/} and the content of the request contains any of the following sub-strings: \texttt{["\#!", "wget", "curl", "tftp"]}. The first sub-string, \texttt{\#!}, represents a shebang character sequence read by Unix-based operating systems to indicate which interpreter should be used when executing a bash script \citep{Shebang}. For an example of a multi-binary bash script used for botnet propagation, see Appendix \ref{appendix_a3}.

Upon collecting all malware binary URLs, each the Top Level Domain (if present), IP address, and host corresponding to each URL is validated before proceeding with malware binary analysis. Using python libraries \texttt{tld} and \texttt{tldextract} \citep{TLD, TLDExtract}, the Top Level Domain of each URL is extracted and checked against a list of ignored TLDs, including \texttt{.gov, .mil} and \texttt{.arpa}. The host-name and IP address of each URL are identified using the builtin python \texttt{socket} library. \citep{PythonSocket} Once identified, the URL, host-name and IP address are used to create a new \texttt{MalwarePayload} database entry. If an instance of the URL already exists, it's corresponding entry is updated, and the URL is dropped from the list of URLs awaiting malware analysis. When creating an entry, the worker will determine if the malware payload is self-hosted by the source IP address attempting to infect the honeypot by matching the packet's source IP address with the IP address identified from the extracted URL. 

\subsection{Botnet traffic classification}

Following the extraction of URLs from a given honeypot packet, the worker will infer the classification of both the source and payload IP addresses based on the context of the extracted URLs and the command-line code injection string's contents. If one or more URLs was successfully extracted and at least one URL is self-hosted by the packet's source IP address, the worker will classify the source/payload IP address as a "Malicious Bot". Bad actors use malicious Bots to self-propagate botnets without the need for an external payload server. Malware binaries are downloaded onto the infected machine, used as a download host when attempting to infect other machines.

If the IP address of the payload URL does not match the source IP, the payload host is classified as a "Payload Server", and the source IP address is classified as a "Report Server". As seen in botnet variants such as Mirai, as infected bots scan for vulnerable devices, they will report such findings to a report server. The report server will attempt to infect the device through command-line injection, using malware remotely hosted on a separate payload server. For simplicity, both infected hosts and report servers that attempt to infect devices using malware hosted on payload servers are classified as report servers.

Alternatively, suppose no URLs are extracted from the honeypot packet payload or post\_data strings. In that case, the worker will use additional information provided by the Bad Packets API to determine if the packet contains characteristics representative of passive botnet activity, such as port scanning. By monitoring packets received by honeypots, all packets are evaluated in terms of target port usage and payload exploit characteristics to identify various Common Vulnerability Exploit (CVE) tags and descriptive categories such as "Mirai-like scan". Bad Packets detect Mirai-like scans by analysing the TCP sequence number of a given packet and checking if it is equal to the targeted device's IP address, as shown in the Mirai source code snippet shown below. \citep{BadPacketsMirai}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.75\linewidth]{images/mirai-like-signature.png}
    \caption{Mirai TCP sequence source-code. Snippet provided by \citet{BadPackets}}
    \label{fig:mirai_like_scan} 
\end{figure}

Using the additional tag information provided by Bad Packets, VisiBot can infer if a packet is associated with botnet scanning activity. A honeypot packet that does not contain any payload URLs and indicates either Mirai-like or otherwise general port scanning activity is classified as a "Bot".  

\subsection{Honeypot Packet Processing}

Following the identification and classification of the source IP and payload IP addresses of a given honeypot packet, each IP address is parsed for additional meta-data required for botnet analysis. The geographic information for each classified IP address is looked up Using various MaxMind GeoIP2 databases \citep{MaxMind} and is stored within the VisiBot database. Such geographic metadata includes the latitude and longitude, city, country, and the continent of a given IP address. Privacy and hosting information for a given IP address is identified using the IPInfo Privacy Detection API \citep{IPInfo}, allowing for identification of servers provided by hosting services and the detection of a proxy, VPN, or tor service. Lastly, Autonomous System history information is collected for each IP address using the \texttt{ipwhois} python module, an IP WHOIS lookup tool that sources ASN information directly from Internet Service Registries such as AFRINIC, APNIC, and RIPE NCC \citep{Afrinic, Apnic, RipeNCC}.

Following the IP address meta-data storage, a new event log entry is created for each IP address, indicating the event classification label and the time and date of occurrence. Additionally, all relationships between a given packet's source IP address and payload IP addresses are stored within the database, specifying the source and destination IP addresses of IP address relationships and the time at which the connection/relationship between IP addresses was logged. Lastly, the packet JSON data sourced from the Bad Packets honeypot service is stored directly within the VisiBot database. Each record contains valuable information for botnet analysis, such as the targeted port, request user-agent, Bad Packets tags, and event count. The entity-relationship structure of all documents stored within the VisiBot database is shown in Appendix \ref{appendix_a1}.

Once complete, the VisiBot worker will iterate over the list of extracted payloads URLs and sequentially send HTTP requests to a remotely hosted malware sandbox server for analysis, along with a specified execution time in seconds. In this case, the worker specifies that the binary must be executed for a total of 30 seconds before termination. Following the creation of a malware analysis task, the sandbox server will respond with a unique \texttt{task\_id} identifier, which is stored within the VisiBot database along-side the identifier of the payload being analysed. Upon malware analysis completion, the sandboxing server will send an analysis report back to the VisiBot Processing System through a REST API. The received report is then analysed for candidate botnet Command \& Control server and Peer-to-Peer node identification. For a full low-level overview of the VisiBot Processing System, please refer to the flow diagram shown in Appendix \ref{appendix_a4}.

\subsection{LiSa Sandbox Integration}

Developed by Daniel Uhříček, the LiSa Sandbox \citep{LiSa} is an open-source, scalable Linux Sandbox platform for executing and analysing malware binaries of various architectures, including CPU architectures such as MIPS, ARM, x86\_64, i386, and aarch64. Like the VisiBot Processing System, LiSa is a multi-container docker application that invokes the message-broker design pattern using Celery and RabbitMQ as message broker \citep{Celery, RabbitMQ}.
Accessible through both a web dashboard and REST API, the LiSa sandbox allows for remote static and dynamic analysis of binary executables. The number of workers used to analyse binaries can be scaled in the same way VisiBot workers are scaled, using the \texttt{-scale worker=N} argument when starting the service using \texttt{docker-compose}. This allows for a scaled and easily distributable system for performing remote malware analysis, enabling multiple binaries to be processed at any given time. 

Static analysis information is directly extracted from uploaded binaries using Radare2 \citep{Radare2}, a comprehensive binary analysis framework, allowing for the identification of a given malware binary's target CPU architecture, endianness, operating system, and more. Dynamic and network analysis is performed through the direct execution of a malware binary within a sandbox environment. Each binary is executed within the QEMU virtual machine using an embedded Linux image that matches the binary CPU architecture. As LiSa supports five different architectures, an embedded Linux image was created for each architecture using Buildroot \citep{Buildroot}. A variety of dynamic analysis information is logged during execution, including packet data, machine log information, process trees, system calls, opened files, and program output. Using the collection of static and dynamic data collected, LiSa generates a report for each malware analysis task which contains network analysis information such as IP address endpoints, HTTP requests, DNS queries, telnet data and IRC messages. Users are also given the option to provide an API key for automatic aggregation of various anti-virus scanning services through VirusTotal \citep{VirusTotal}. As the VirusTotal scan reports of identified malware binaries are actively used throughout VisiBot analysis, this service was enabled using an academic VirusTotal API key.

\subsubsection{Modifications to LiSa}

Despite the extensive feature-set provided by the default LiSa sandbox configuration, some limitations were encountered when integrating the sandbox into the VisiBot Processing System. Several modifications were made to the LiSa sandbox source-code via a public GitHub fork of the LiSa Sandbox \citep{LiSaModified} to mitigate such issues.

The first issue encountered was that binaries had to be provided as file attachments when creating analysis requests through the LiSa REST API. The LiSa sandbox API was modified to accept an additional \texttt{url} parameter the URL of a binary to be provided instead of the file itself, as downloading and storing malware binaries onto the VisiBot server may result in potential security issues.

Following the manual inspection of several LiSa analysis reports, the malware reports indicated that many malware binaries were obfuscated using packing software to prevent the extraction of strings. Any attempt to extract strings from a packed malware binary would result in un-readable and heavily obfuscated output. Commonly incorporated by malware authors as a means of obfuscation, a packed binary contains a payload of compressed or encrypted code unpacked into the program's address space at run-time. \citep{Roundy2013} This process ensures that analytical software tools, such as the \texttt{strings} command-line tool \citep{Strings} used by LiSa, output obfuscated information. Modifications were made to the LiSa sandbox to allow for the detection and unpacking of malware packed using the UPX packing tool \citep{UPX}. UPX a popular tool used by botnet perpetrators for obfuscating the contents of Linux/Unix executables. This tool leaves an identifier signature in the strings of a packed malware, allowing for quick identification when parsing the output of the \texttt{strings} command executed by the LiSa analysis worker. If the substring "UPX!" is found in the strings of a binary, the worker will attempt to unpack the binary using the command \texttt{upx --decompress path/to/file}. Following this, the string values of the unpacked binary are collected by re-running \texttt{strings} on the binary.

Lastly, when integrating the LiSa sandbox with the VisiBot Processing System, various communication-based limitations were encountered. As the LiSa sandbox's source code only allows for one-way communication through a REST API, there was no efficient way for the VisiBot Processing System to detect when analysis tasks were complete. An initial solution was to query the LiSa API for task status updates repeatedly, yet this proved highly inefficient and ultimately introduced several reliability issues. Thus, the VisiBot Processing System hosts a minimal REST API written in Flask, \citep{Flask} used by LiSa sandbox workers to send back completed analysis tasks. Adding a REST API to the processing system allows for a robust two-way communication system between VisiBot and the LiSa sandbox server.

Hosted within a separate docker container, the VisiBot Flask API accepts two types of HTTP request from the LiSa Sandbox via endpoints \textit{/api/lisa-analysis/success/<task\_id>} and \textit{/api/lisa-analysis/failure/<task\_id>} respectively. Additional modifications were made to the LiSa sandbox source-code to send analysis or failure information to the VisiBot API following task completion. If an analysis task succeeds, LiSa will send the malware analysis report back to the VisiBot Processing System for further analysis. Whereas, if an analysis task fails, stack-trace information is returned to VisiBot to handle failed payloads. Responses are handled by creating corresponding Celery tasks, which are eventually consumed and carried out by available VisiBot workers. Failed tasks are processed based on the type of exception generated during analysis. For example, if a \texttt{UnicodeDecodeError} was raised, this indicates that the extracted payload URL points to a non-executable file. Thus, the MalwarePayload document (and all other related documents) can be removed from the MongoDB database.

\subsection{Malware Analysis Information Extraction}

Before applying identification heuristics, the worker will first attempt to parse the top-most recurring malware keyword from a list of anti-virus scan results obtained from VirusTotal. However, as many anti-virus services do not follow the same naming convention when labelling the type of malware detected, additional steps were taken to standardise the keyword extraction process by removing punctuation, case sensitivity, and generic keywords such as \texttt{Trojan, Malware, Worm}, etc. What is left is a list of less common keywords for each malware analysis result. These lists are combined, and the most commonly recurring string is used as the keyword identifier for the analysed malware. For an example of this process, please refer to Appendix \ref{appendix_a5}.

Following this, the worker will parse each of the binary strings collected during the static analysis stage of the LiSa sandbox analysis, such that all strings of significance are extracted. Such strings of significance may match regular expression patterns for IPv4 and IPv6 addresses, URLs, and domains. This step was necessary, as a full list of strings extracted by LiSa is often too large to store within a database. Additionally, the extraction of such features allows for ease-of-use in future research.

\subsection{Application of heuristics}

After processing, the next stage of the LiSa analysis worker task is to identify all candidate Command \& Control Servers and Peer-to-Peer botnet nodes associated with a given binary by applying four identification heuristics on the provided network analysis information logged during malware execution. The four heuristics used by VisiBot are as follows:

\begin{enumerate}[i]
    \item The infected host performs a Peer-to-Peer DNS Query during network analysis.
    \item The infected host performs a data-transaction with a foreign IP address.
    \item Interaction between the infected host and hard-coded IP address in malware binary.
    \item Interaction between the infected host and blacklisted Command \& Control Server IP address.
\end{enumerate}

\subsubsection{Heuristic (i)}

The first heuristic is primarily used to differentiate between centralised and de-centralised Peer-to-Peer botnets. By analysing the DNS queries made by a given malware sample during sandbox analysis, we can infer that the malware communicates through Peer-to-Peer networks if any of the given domains fall within a list of known bit-torrent services. As de-centralised botnets often use distributed hash-tables as a means of communicating with other bots and the botnet owner from within a peer-to-peer network, a device infected with peer-to-peer botnet malware may attempt to look up a distributed hash table using a common bit-torrent service. For example, a botnet may query the domain \textbf{dht}.bittorrent.com as part of the distributed hash-table lookup process. Thus, the VisiBot Processing system identifies if this heuristic is satisfied by checking if any of the DNS queries invoked during malware analysis point to a short-list of domain names for known Peer-to-Peer services. The VisiBot Processing System matches all DNS queries collected from the network traffic a given binary with the below string-patterns:

\begin{itemize}
    \item \texttt{.utorrent.com}
    \item \texttt{.transmissionbt.com}
    \item \texttt{.bittorrent.com}
    \item \texttt{.debian.org}
\end{itemize}

If any of the above domain patterns are matched, we deduce that the heuristic \textit{i)} is satisfied. However, as this heuristic only serves as an indication of Peer-to-Peer network activity, it cannot be used exclusively for Peer-to-Peer botnet identification. Instead, it must be used in conjunction with heuristic \textit{ii)}, such that botnet activity can be identified.

\subsubsection{Heuristic (ii)} A data transaction may occur during network analysis of a malware binary when the infected host sends a series of bytes to an external IP address and receives a stream of bytes in response. This activity may include hand-shakes or communication between an infected host and C2 server, downloading a binary from a remote Payload Server, or interactions between peer-to-peer botnet nodes. Thus, this heuristic allows for the distinction between benign and potentially significant network traffic, as IP addresses that send and receive information to/from an infected host will satisfy this heuristic. If both heuristics \textit{i)} and \textit{ii)} are satisfied, it is deduced that the corresponding IP address \textit{ii)} may be a potential peer-to-peer botnet node. However, if only heuristic \textit{i)} is satisfied, it is inferred that the IP address may be a potential (candidate) Command \& Control server. Notably, this classification will consider any data transactions between an infected host and a Payload server as possible C2 activity, as the botnet owner may also use the Payload Server for Command \& Control.

\subsubsection{Heuristic (iii)} As it is common for centralised botnet malware to include hard-coded IP addresses and domains used for C2 communication, the heuristic \textit{iii)} infers that any IP address logged during network analysis that is contained within a list of hard-coded IPv4 addresses from the binary's source may be a potential Command \& Control server. All endpoints are checked against a list of hard-coded IPv4 strings extracted from the LiSa analysis process's previous stage. If any match occurs, then the heuristic \textit{iii)} is satisfied, and the IP address will be classified as a candidate Command \& Control server.

\subsubsection{Heuristic (iv)} If any IP address logged during the network analysis is blacklisted as a known Command \& Control server, the heuristic \textit{iv)} is satisfied. The VisiBot Processing system checks the blacklist status of each IP address endpoint logged during malware analysis using various blacklist services, including those provided by Barracuda Central, abuse.ch, SpamRats, Sorbs DNSBL, and Spamhaus. \cite{BarracudaCentral, AbuseCh, Spamrats, SorbsDnsbl, SpamhausZen} If any IP address has previously been blacklisted as a C2,  the IP address is classified as a candidate Command \& Control server.

Following the above application of heuristics, each IP address endpoint logged during network analysis will be classified either as a candidate C2, a Peer-to-Peer Node, or as benign traffic, which is ignored. A new C2 or P2P entry is added to the VisiBot database depending on which heuristics are satisfied. Followed this, a variety of additional meta-data is collected from the given IP address and stored within the VisiBot database, including geographic information, ASN history, IPinfo Privacy information, and a new event log entry. Following meta-data collection, connection records are created between the analysed payload's IP address and all malicious C2/P2P IP addresses identified during analysis. Lastly, the LiSa analysis report is refined and stored within the VisiBot database and all significant strings and the identified VirusTotal malware keyword. Once the analysis is complete, the worker will consume another LiSa analysis task from the VisiBot broker and repeat the above steps.

% =========================================


\section{Interactive Web Visualisation}

A significant component of the VisiBot Processing System is that the information collected can be easily visualised. A map-based web application was created to provide an interactive visualisation of all botnet traffic detected by the VisiBot Processing System within a 24-hour window. The web application was designed and implemented following the Model View Controller (MVC) design pattern. The development of the front-end presentation layer and back-end data interaction layer are separate, allowing for a separation of concerns. The model used is the same MongoDB database \citep{MongoDB} utilised by the VisiBot Processing System. Users can interact with various aspects of the model through a front-end visualisation layer written in the Nuxt.js \cite{NuxtJS} JavaScript framework. Express.js \citep{ExpressJS} is a flexible web application framework written in Node.js \citep{NodeJS}, often used as a controller within the MVC design pattern.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.75\linewidth]{flowcharts/frontend_flow_diagram.png}
    \caption{Server Architecture Diagram: VisiBot Web Application}
    \label{fig:frontend_server_architecture} 
\end{figure}

\newpage

The back-end Exprss.js REST API communicates with the VisiBot MongoDB database using Mongoose, an Object Data Modelling (ODM) library for MongoDB. \citep{Mongoose} Upon a client sending an HTTP request to the API, the Express.js server will query the MongoDB database directly using Mongoose and returns documents to the client in the standard JSON format. As Express, Mongoose, and Nuxt.js are JavaScript-based, the JSON-based document structure used to represent MongoDB documents is natively supported across all three frameworks, allowing for extensive flexibility without introducing overhead such as JSON serialisation. In conjunction with Nuxt.js and Express.js, several \texttt{npm} packages were also used throughout development. The BootstrapVue \citep{BootstrapVue} library was used with Nuxt.js to develop a modern, flexible, and intuitive user interface using the Bootstrap CSS framework.

\subsection{Geographic Clustering and Networks}

An interactive, cluster-based map was developed using \citep{LeafletJS} to allow for real-time interaction with the various botnet entities identified by the VisiBot Processing System. This map displays a clustered representation of the geographic locations of all entities identified within the last 24 hours, with each IP address displayed as a coloured marker. The colour of the marker depends on the classification of traffic coming from the IP address. As the user zooms in on the map, the clusters dynamically become smaller in size, allowing for the user to interact with the full extent of the map without experiencing information overload or the performance side-effects of displaying too many markers at once. An example of the VisiBot Web Application interface is shown below:

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1.0\linewidth]{images/visibot_screenshot_cluster.png}
    \caption{VisiBot Web Application}
    \label{fig:visibot_screenshot_cluster} 
\end{figure}

When a cluster is selected, the map will automatically zoom in and disseminate the clustered markers into smaller clusters or individual markers, depending on the cluster density. When a marker is selected, the user is presented with three options. The first option allows the user to view a network of all of the associated connections that the current IP address has with other botnet entities identified by VisiBot. For example, a candidate C2 server's connections may include interactions with payload servers, report servers, or infected bots. These connections are generated using the \texttt{graphLookup} document aggregation \citep{graphLookup} provided by MongoDB, allowing for full traversal of the connection tree of a given IP address. All coordinates collected using \texttt{graphLookup} for a given IP address are drawn as lines on the map, as demonstrated in the Peer-to-Peer connections example shown in appendix \ref{appendix_a6}.


% =========================================


\section{Software Development Practices}

\subsubsection{Issue Tracking}

To manage the many deadlines, priorities, tasks, and to-do-lists involved throughout the development of VisiBot, Trello, a Kanban-style, web-based, ticket tracking application \citep{Trello} was used.  Throughout the development of VisiBot, various issues were created and managed using Trello. Using Trello, I sorted all tickets related to the VisiBot development process between three lists based on development status: 'Backlog', 'In Progress', and 'Complete'. All tickets awaiting development are stored in a ticket backlog, with some tickets also being organised based on feature priority. The use of a board-based ticket management system ensures that all priorities and features are displayed coherently. More-so, Trello also proved highly beneficial for tracking and managing various project-related deadlines and to-do-lists. Each ticket can be assigned a due-date timestamp, encapsulate lists of sub-tasks using interactive checklist boxes. 

\subsubsection{Quality Assurance}

Throughout development, linting tools and unit testing tools were used as a means of quality assurance. Several unit tests were written using the unittest \citep{uniittest} python testing framework, ensuring reliable and robust code. Pylama, an auditing/linting tool for Python, \citep{pylama} was frequently used to ensure standardised coding style and readability. Pylama wraps various linting tools into a single code auditing tool, including popular linters such as Pylint, PyFlakes, and pycodestyle. The combination of various linting tools enables strict enforcement of various best practices followed by Python programming professionals, including official style guides, such as the PEP-8 style guide written by \citet{PEP8}. Additionally, ESLint, \citep{ESLint} a static analysis linting tool for JavaScript, was also used for actively identifying problems in both Nuxt.js and Express.js applications, identifying issues such as consistency, readability, and correctness. Both Python and JavaScript linting tools proved excellent for identifying an abundance of errors and inconsistencies amongst the VisiBot code-base, minimising potential issues that may arise from inconsistent or poorly written code.

\subsubsection{Source Code Management}

Git \citep{Git} was used throughout development for managing and versioning the VisiBot source code throughout the project development life-cycle. Git is a Source Code Management (SCM) tool that allows for versioning control amongst various other beneficial features. All source-code managed using the Git SCM was also remotely hosted on a private repository using the GitHub \citep{GitHub} code-hosting and collaboration platform. Throughout development, I followed a trunk-based branching strategy such that all SCM changes were implemented as small, frequent commits to the master/main branch of the repository. As only one developer carried out the development of VisiBot, branching strategies such as feature branching were deemed unnecessary, as the likelihood of encountering merge conflicts within a single-developer work environment was minimal. Before pushing any local changes to the remote repository, all code was automatically tested locally using Git pre-push hooks. \citep{PrePushHooks} By hooking a shell script onto the \texttt{git push} command, the contents of the script is executed and evaluated before the push request being executed. If the script exits with an error, the user must fix the errors raised during the pre-push script execution before allowing for changes to be pushed to a remote branch. Within the context of VisiBot, code linting and unit testing stages were automatically executed locally before pushing to a remote GitLab repository using a pre-push script. This script executes various unit tests, and the \texttt{pylama} and \texttt{eslint} linting tools within \texttt{src/processing} and \texttt{src/webapp} directories consecutively. By doing so, quality assurance is maintained by ensuring that if either of the linting tools or unit tests fail, the push request will be aborted until all issues are resolved. All unit testing and linting tools are also automatically performed through a Continuous Integration (CI) Pipeline deployed using the Travis CI \citep{TravisCI} Continuous Integration service. Integratable with GitHub, Travis CI was used throughout development to automate the linting and unittesting quality assurance measurements whenever code is pushed to a monitored GitHub branch, such as the master branch. If the pipeline fails, all maintainers of the branch are alerted of the failure and are responsible for fixing any issues. The automatic testing of code ensures that even if a developer pushes code without testing locally, all code is tested before merging into the master branch.
